# Kaggle Berlin Tutorial

*Instructor: Ezzeri Esa*

## Installation Notes
This tutorial requires *NumPy*, *scikit-learn* and *IPython* with the IPython Notebook. If
you're not sure how to install these packages, we recommend the free [Anaconda 
distribution](http://continuum.io/downloads).

We will be reviewing the materials with the IPython Notebook. You should be able to type
	
	ipython notebook
	
in your terminal window and see the notebook panel load in your web browser.


## Downloading the Tutorial Materials

You can clone the material in this tutorial using git as follows:

	git clone git://github.com/savarin/kaggle-berlin-tutorial.git

Alternatively, there is a link above to download the contents of this repository as a zip
file.


## Static Viewing

The notebooks can be viewed in a static fashion using the [nbviewer](http://nbviewer.ipython.org)
site, as per the links in the sectionbelow. However, we recommend reviewing them
interactively with the IPython Notebook.


## Presentation Format

The tutorial will cover data manipulation using pandas - loading data, and cleaning data. 
We'll then use scikit-learn to make predictions. By the end of the session, we would have
worked on the Kaggle Titanic competition [Kaggle Titanic competition](https://www.kaggle.com/c/titanic-gettingStarted)
from start to finish, through a number of iterations of increasing sophistication.
- [Section 1-0 - First Cut.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%201-0%20-%20First%20Cut.ipynb)
- [Section 1-1 - Filling-in Missing Values.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%201-1%20-%20Filling-in%20Missing%20Values.ipynb)
- [Section 1-2 - Creating Dummy Variables.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%201-2%20-%20Creating%20Dummy%20Variables.ipynb)
- [Section 1-3 - Parameter Tuning.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%201-3%20-%20Parameter%20Tuning.ipynb)

Time-permitting, we would cover the following materials.
- [Section 1-4 - Building Pipelines.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%201-4%20-%20Building%20Pipelines.ipynb)
- [Section 1-5 - Final Checks.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%201-5%20-%20Final%20Checks.ipynb)
- [Section 2-1 - Support Vector Machines.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%202-1%20-%20Support%20Vector%20Machines.ipynb)
- [Section 2-2 - SVM with Parameter Tuning.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Section%202-2%20-%20SVM%20with%20Parameter%20Tuning.ipynb)
- [Appendix A - Cross-Validation.ipynb](http://nbviewer.ipython.org/github/datapress/kaggle-titanic/blob/master/notebooks/Appendix%20A%20-%20Cross-validation.ipynb)

A [Kaggle account](https://www.kaggle.com/account/register) would be required for the
purposes of making submissions and reviewing the performance of the model on the leaderboard.


