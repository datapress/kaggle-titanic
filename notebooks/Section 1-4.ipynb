{
 "metadata": {
  "name": "",
  "signature": "sha256:3148c76098990d24a47023eab30bfbf67db1800d20647ed4f809dd18339337c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Section 1-4: Building Pipelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Problem of 'snooping'. Get around by building pipeline + imputation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pandas - Extracting Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "df = pd.read_csv('../data/titanic_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pandas - Cleaning Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unlike previously, will leave NA in Age, fill with average of each fold"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
      "\n",
      "age_mean = df['Age'].mean()\n",
      "\n",
      "from scipy.stats import mode\n",
      "\n",
      "mode_embarked = mode(df['Embarked'])[0][0]\n",
      "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
      "\n",
      "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
      "\n",
      "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
      "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
      "\n",
      "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
      "\n",
      "cols = df.columns.tolist()\n",
      "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
      "\n",
      "df = df[cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Will fill NA values in Age with -1\n",
      "\n",
      "Because of the following bug we cannot use NaN as the missing value marker, use a negative value as marker instead:\n",
      "https://github.com/scikit-learn/scikit-learn/issues/3044"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.fillna(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Review dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 891 entries, 0 to 890\n",
        "Data columns (total 11 columns):\n",
        "Survived       891 non-null int64\n",
        "PassengerId    891 non-null int64\n",
        "Pclass         891 non-null int64\n",
        "Age            891 non-null float64\n",
        "SibSp          891 non-null int64\n",
        "Parch          891 non-null int64\n",
        "Fare           891 non-null float64\n",
        "Gender         891 non-null int64\n",
        "Embarked_C     891 non-null float64\n",
        "Embarked_Q     891 non-null float64\n",
        "Embarked_S     891 non-null float64\n",
        "dtypes: float64(5), int64(6)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = df.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scikit-learn - train model with training data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, imputer. Second, pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "imputer = Imputer(strategy='mean', missing_values=-1)\n",
      "\n",
      "classifier = RandomForestClassifier(n_estimators=100)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', classifier),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note slight change made to parameter_grid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameter_grid = {\n",
      "    'clf__max_features': [0.5, 1],\n",
      "    'clf__max_depth': [5, None],\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "replace classifier by pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search = GridSearchCV(pipeline, parameter_grid, cv=5, verbose=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.fit(train_data[0::,1::], train_data[0::,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=5 .........................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=5, score=0.843575 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=5 .........................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=5, score=0.803371 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=5 .........................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=5, score=0.797753 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=5 .........................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=5, score=0.848315 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=5 .........................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=5, score=0.837079 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=5 ...........................\n",
        "[GridSearchCV] .. clf__max_features=1, clf__max_depth=5, score=0.865922 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=5 ...........................\n",
        "[GridSearchCV] .. clf__max_features=1, clf__max_depth=5, score=0.792135 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=5 ...........................\n",
        "[GridSearchCV] .. clf__max_features=1, clf__max_depth=5, score=0.769663 -   0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=5 ...........................\n",
        "[GridSearchCV] .. clf__max_features=1, clf__max_depth=5, score=0.859551 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=5 ...........................\n",
        "[GridSearchCV] .. clf__max_features=1, clf__max_depth=5, score=0.831461 -   0.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=None ......................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=None, score=0.826816 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=None ......................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=None, score=0.803371 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=None ......................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=None, score=0.803371 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=None ......................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=None, score=0.831461 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=0.5, clf__max_depth=None ......................\n",
        "[GridSearchCV]  clf__max_features=0.5, clf__max_depth=None, score=0.820225 -   0.3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=None ........................\n",
        "[GridSearchCV]  clf__max_features=1, clf__max_depth=None, score=0.837989 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=None ........................\n",
        "[GridSearchCV]  clf__max_features=1, clf__max_depth=None, score=0.780899 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=None ........................\n",
        "[GridSearchCV]  clf__max_features=1, clf__max_depth=None, score=0.775281 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=None ........................\n",
        "[GridSearchCV]  clf__max_features=1, clf__max_depth=None, score=0.814607 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[GridSearchCV] clf__max_features=1, clf__max_depth=None ........................\n",
        "[GridSearchCV]  clf__max_features=1, clf__max_depth=None, score=0.842697 -   0.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.3s\n",
        "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.6s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "GridSearchCV(cv=5,\n",
        "       estimator=Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values=-1, strategy='mean', verbose=0)), ('clf', RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
        "            verbose=0))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'clf__max_features': [0.5, 1], 'clf__max_depth': [5, None]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=3)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
      "grid_search.best_score_\n",
      "grid_search.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "{'clf__max_depth': 5, 'clf__max_features': 0.5}"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = RandomForestClassifier(n_estimators = 100, max_features=0.5, max_depth=5)\n",
      "model = model.fit(train_data[0::,1::],train_data[0::,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scikit-learn - use model to make prediction / making predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test = pd.read_csv('../data/titanic_test.csv')\n",
      "\n",
      "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fill NA in test data with mean is fine, since no analogous problem of snooping"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test['Age'] = df_test['Age'].fillna(age_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
      "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
      "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
      "                            else x['Fare'], axis=1)\n",
      "\n",
      "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
      "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
      "                axis=1)\n",
      "\n",
      "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
      "\n",
      "test_data = df_test.values\n",
      "\n",
      "output = model.predict(test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pandas - preparing submission"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
      "\n",
      "\n",
      "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
      "df_result.to_csv('../results/titanic_1-4.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Your submission scored 0.77990, which is not an improvement of your best score. Keep trying! "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}